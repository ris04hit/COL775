{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T13:14:24.697408Z","iopub.status.busy":"2024-03-12T13:14:24.696883Z","iopub.status.idle":"2024-03-12T13:14:27.983413Z","shell.execute_reply":"2024-03-12T13:14:27.982487Z","shell.execute_reply.started":"2024-03-12T13:14:24.697360Z"},"trusted":true},"outputs":[],"source":["# imports\n","import sys\n","import os\n","import cv2\n","import numpy as np\n","import pickle\n","import torch\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Utils\n","\n","# Creating directory\n","def create_dir(addr):\n","    if not os.path.exists(addr):\n","        os.mkdir(addr)\n","\n","# Delete folder and its content\n","def remove_folder_contents(folder):\n","    for the_file in os.listdir(folder):\n","        file_path = os.path.join(folder, the_file)\n","        try:\n","            if os.path.isfile(file_path):\n","                os.unlink(file_path)\n","            elif os.path.isdir(file_path):\n","                remove_folder_contents(file_path)\n","                os.rmdir(file_path)\n","        except Exception as e:\n","            print(e)\n","\n","# Addresses\n","\n","# Data Address\n","data_address = \"data\"\n","\n","# Raw data\n","raw_address = \"../input/indian-birds/Birds_25\"\n","raw_train = \"../input/indian-birds/Birds_25/train\"\n","raw_test = \"../input/indian-birds/Birds_25/test\"\n","raw_val = \"../input/indian-birds/Birds_25/val\"\n","\n","# Processed data\n","processed_address = \"data/processed\"\n","cat_address = \"data/processed/cat.pkl\"\n","stat_address = \"data/processed/stats.npz\"\n","\n","# Temp Address\n","temp_address = \"temp\"\n","\n","# Results\n","result_address = \"results/\"\n","base_model_result = \"results/base_model\"\n","\n","# Init Structure\n","create_dir(temp_address)\n","create_dir(data_address)\n","create_dir(processed_address)\n","create_dir(raw_address)\n","create_dir(raw_train)\n","create_dir(raw_test)\n","create_dir(raw_val)\n","create_dir(result_address)\n","\n","# Constants\n","random_seed = 68\n","n = 2\n","r = 25\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Statistical Calculation\n","\n","# Loading statistical data\n","def load_stat(stat_addr):\n","    x_stats = np.load(stat_addr)\n","    x_mean = x_stats['mean']\n","    x_std = x_stats['std']\n","    return x_mean, x_std\n","\n","# Saving statistical data\n","def save_stat(lin_sum, quad_sum, stat_addr, total_ct):\n","    x_mean = (lin_sum/total_ct).astype(np.float64)\n","    x_std = np.sqrt(quad_sum/total_ct - x_mean**2).astype(np.float64)\n","    np.savez_compressed(stat_addr, mean = x_mean, std = x_std)\n","    print(\"Saved statistical processed data\")\n","\n","# Partition data into smaller fragments and returns sum and quad sum\n","def moment_data(category, shape, address, stat_addr, mode):\n","    # Reading Data and Preprocessing it\n","    lin_sum, quad_sum = np.zeros(shape, dtype=np.float64), np.zeros(shape, dtype=np.float64)\n","    ct_list = []\n","    for cat in category:\n","        cat_path = os.path.join(address, cat)\n","        ct_list.append(len(os.listdir(cat_path)))\n","        \n","        # Checking if already present\n","        if os.path.exists(stat_addr) or mode==1:\n","            continue\n","        \n","        # Reading each image of particular category\n","        count = 0\n","        for img_name in sorted(os.listdir(cat_path)):\n","            img_path = os.path.join(cat_path, img_name)\n","            img = np.array(cv2.imread(img_path))\n","            lin_sum += img.astype(np.float64)\n","            quad_sum += np.square(img.astype(np.float64))\n","            count += 1\n","        \n","        # log\n","        print(f\"Read {cat}\\tindex: {category.index(cat)}\\tnum: {count}\")\n","\n","    if mode == 0:\n","        print(\"Read Train Data\")\n","    else:\n","        print(\"Read Test Data\")\n","\n","    return lin_sum, quad_sum, ct_list\n","\n","# Reading data fragments and normalizing them\n","def normalize(addr, category, processed_x_addr, processed_y_addr, norm, overwrite):\n","    ct = 0\n","    for cat in category:\n","        cat_addr = os.path.join(addr, cat)\n","        for img_name in sorted(os.listdir(cat_addr)):\n","            # Save Address\n","            x_addr = os.path.join(processed_x_addr, f'{ct}.pt')\n","            y_addr = os.path.join(processed_y_addr, f'{ct}.pt')\n","            if not overwrite and os.path.exists(x_addr) and os.path.exists(y_addr):\n","                ct += 1\n","                continue\n","            \n","            # Reading image\n","            img_path = os.path.join(cat_addr, img_name)\n","            img = np.array(cv2.imread(img_path), dtype=np.float64)\n","            \n","            # Normalizing image\n","            norm_img = norm(img)\n","            x = torch.tensor(norm_img)\n","            \n","            # Getting y\n","            y = np.zeros((len(category),), dtype=np.float64)\n","            y[category.index(cat)] = 1\n","            y = torch.Tensor(y)\n","            \n","            # Saving image\n","            torch.save(x, x_addr)\n","            torch.save(y, y_addr)\n","            \n","            # Incrementing counter\n","            ct += 1\n","        \n","        print(f\"Preprocessed\\tindex: {category.index(cat)}\\t{cat}\")\n","\n","# Preprocessed data\n","def preprocess(address, mode, overwrite = False, cat_addr = None, stat_addr = None, shape = (256, 256, 3)):\n","    '''\n","    mode = 0: Training Mode\n","    mode = 1: Testing Mode\n","    '''\n","\n","    if mode not in [0, 1]:\n","        raise Exception(\"Not a Valid Mode\")\n","\n","    # Identifying Categories\n","    if mode == 0:\n","        category = sorted(os.listdir(address))\n","        \n","        # Saving categories\n","        if overwrite or not os.path.exists(cat_addr):\n","            with open(cat_addr, 'wb') as cat_file:\n","                pickle.dump(category, cat_file)\n","        print(\"Assigned Categories\")\n","        \n","    elif mode == 1:\n","        # Reading Category array\n","        with open(cat_addr, 'rb') as cat_file:\n","            category = pickle.load(cat_file)\n","        print(\"Read Categories\")\n","    \n","    # count of images and their moments\n","    lin_sum, quad_sum, ct_list = moment_data(category=category, shape=shape, address=address, stat_addr=stat_addr, mode=mode)\n","        \n","    # Normalizing Data\n","    if mode == 0 and (overwrite or not os.path.exists(stat_addr)):\n","        save_stat(lin_sum=lin_sum, quad_sum=quad_sum, stat_addr=stat_addr, total_ct=sum(ct_list))\n","    x_mean, x_std = load_stat(stat_addr)\n","        \n","    # # Function for normalization\n","    # norm = lambda img: np.divide((img - x_mean), x_std, out = np.zeros_like(x_mean), where = x_std!=0)\n","\n","    # # Creating train directory\n","    # create_dir(processed_x_addr)\n","    # create_dir(processed_y_addr)\n","\n","    # # Reading Saved Files and Normalizing them\n","    # normalize(addr=address, category=category, processed_x_addr=processed_x_addr, processed_y_addr=processed_y_addr, norm=norm, overwrite=overwrite)\n","\n","    return category\n","\n","# Function Call\n","category = preprocess(address=raw_train, mode=0, overwrite=False, cat_addr=cat_address, stat_addr=stat_address)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# cuda\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Working with {device}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Data Loader\n","def generate_cat_list(address):\n","    cat_list = []\n","    for cat in category:\n","        cat_path = os.path.join(address, cat)\n","        cat_list.append(sorted(os.listdir(cat_path)))\n","    return cat_list\n","\n","# Data Generator for Training Data\n","def data_generator(ind, address, cat_list, device):\n","    for cat_ind in range(len(cat_list)):\n","        if ind < len(cat_list[cat_ind]):\n","            cat_path = os.path.join(address, category[cat_ind])\n","            img_path = os.path.join(cat_path, cat_list[cat_ind][ind])\n","            x = torch.tensor(cv2.imread(img_path), dtype=torch.float64)\n","            y_vec = np.zeros((len(category),))\n","            y_vec[cat_ind] = 1\n","            y = torch.tensor(y_vec, dtype=torch.float64)\n","            return x, y\n","        else:\n","            ind -= len(cat_list[cat_ind])\n","\n","# Data Loader\n","class DataLoader():\n","    def __init__(self, address, cat_list, batch_size, stat_addr, rand_seed = None, randomize = True, device = device):\n","        # Finding number of Data Samples\n","        self.num_data = sum([len(cat_arr) for cat_arr in cat_list])\n","        \n","        # Randomizing if True\n","        np.random.seed(rand_seed)\n","        self.order = np.arange(self.num_data)\n","        \n","        # Assigning Class Variables\n","        self.batch_size = batch_size\n","        self.device = device\n","        self.randomize = randomize\n","        \n","        # Load Statsistical data\n","        self.mean, self.std = load_stat(stat_addr)\n","        self.mean = torch.tensor(self.mean).to(device)\n","        self.std = torch.tensor(self.std).to(device)\n","\n","        # Data Generator Function\n","        self.generate = lambda ind: data_generator(ind, address, cat_list, device = device)\n","        \n","    def __iter__(self):\n","        # Initializing index\n","        self.ind = 0\n","        if self.randomize:\n","            np.random.shuffle(self.order)\n","        return self\n","    \n","    def __next__(self):\n","        # Checking stop condition\n","        if self.ind >= self.num_data:\n","            raise StopIteration\n","        \n","        X, Y = [], []\n","        for i in range(self.batch_size):\n","            # Loading X, Y\n","            x, y = self.generate(self.order[self.ind])\n","            X.append(x.permute(2, 0, 1))    # Channel is first dimension\n","            Y.append(y)\n","            \n","            # Updating index\n","            self.ind += 1\n","            if self.ind == self.num_data:\n","                break\n","        \n","        # Returning data\n","        X = torch.stack(X).to(self.device)\n","        Y = torch.stack(Y).to(self.device)\n","        return X, Y\n","\n","# Creating Data Loader\n","data_loader_train = DataLoader(address=raw_train,\n","                               cat_list=generate_cat_list(raw_train),\n","                               batch_size=batch_size,\n","                               stat_addr=stat_address,\n","                               rand_seed=random_seed)\n","\n","data_loader_test = DataLoader(address=raw_test,\n","                               cat_list=generate_cat_list(raw_test),\n","                               batch_size=batch_size,\n","                               stat_addr=stat_address,\n","                               rand_seed=random_seed)\n","\n","data_loader_val = DataLoader(address=raw_val,\n","                               cat_list=generate_cat_list(raw_val),\n","                               batch_size=batch_size,\n","                               stat_addr=stat_address,\n","                               rand_seed=random_seed)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Model\n","\n","class ResBlock(torch.nn.Module):\n","    def __init__(self, in_channel, out_channel, norm_func, kernel_size=3, stride=1):\n","        super(ResBlock, self).__init__()\n","        \n","        self.conv1 = torch.nn.Conv2d(in_channel, in_channel, kernel_size, stride=1, padding=1, dtype=torch.float64)\n","        self.norm1 = norm_func(in_channel, dtype=torch.float64)\n","        self.activation1 = torch.nn.ReLU()\n","        \n","        self.conv2 = torch.nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding=1, dtype=torch.float64)\n","        self.norm2 = norm_func(out_channel, dtype=torch.float64)\n","        self.activation2 = torch.nn.ReLU()\n","        \n","        self.project = True if (in_channel != out_channel) or (stride != 1) else False\n","        if self.project:\n","            self.conv_project = torch.nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding=1, dtype=torch.float64)\n","\n","    def forward(self, x):\n","        res = x\n","        x = self.conv1(x)\n","        x = self.norm1(x)\n","        x = self.activation1(x)\n","        \n","        x = self.conv2(x)\n","        x = self.norm2(x)\n","        x += self.conv_project(res) if self.project else res\n","        x = self.activation2(x)\n","        \n","        return x\n","\n","class Resnet(torch.nn.Module):\n","    def __init__(self, n, r, norm_func = torch.nn.BatchNorm2d):\n","        super(Resnet, self).__init__()\n","\n","        self.norm = norm_func\n","        \n","        #Input\n","        self.input_layer = []\n","        self.input_layer.append(torch.nn.Conv2d(3, 16, 3, 1, padding=1, dtype=torch.float64))\n","        self.input_layer.append(self.norm(16, dtype=torch.float64))\n","        self.input_layer.append(torch.nn.ReLU())\n","        self.input_layer = torch.nn.Sequential(*self.input_layer)\n","        \n","        # Layer1\n","        self.hidden_layer1 = []\n","        for i in range(n):\n","            self.hidden_layer1.append(ResBlock(16, 16, self.norm))\n","        self.hidden_layer1 = torch.nn.Sequential(*self.hidden_layer1)\n","        \n","        # Layer2\n","        self.hidden_layer2 = []\n","        self.hidden_layer2.append(ResBlock(16, 32, self.norm, stride = 2))\n","        for i in range(n-1):\n","            self.hidden_layer2.append(ResBlock(32, 32, self.norm))\n","        self.hidden_layer2 = torch.nn.Sequential(*self.hidden_layer2)\n","        \n","        # Layer3\n","        self.hidden_layer3 = []\n","        self.hidden_layer3.append(ResBlock(32, 64, self.norm, stride = 2))\n","        for i in range(n-1):\n","            self.hidden_layer3.append(ResBlock(64, 64, self.norm))\n","        self.hidden_layer3 = torch.nn.Sequential(*self.hidden_layer3)\n","            \n","        # Pool Layer\n","        self.pool = torch.nn.AdaptiveAvgPool2d(1)\n","        self.flatten = torch.nn.Flatten()\n","        \n","        # Output Layer\n","        self.output_layer = []\n","        self.output_layer.append(torch.nn.Linear(64, r, dtype=torch.float64))\n","        self.output_layer.append(torch.nn.Softmax(1))\n","        self.output_layer = torch.nn.Sequential(*self.output_layer)\n","\n","    def forward(self, x):\n","        x = self.input_layer(x)\n","        x = self.hidden_layer1(x)\n","        x = self.hidden_layer2(x)\n","        x = self.hidden_layer3(x)\n","        x = self.pool(x)\n","        x = self.flatten(x)\n","        x = self.output_layer(x)\n","        \n","        return x\n","\n","# Setting Random Seed\n","torch.manual_seed(random_seed)\n","resnet_base_model = Resnet(n, r).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T13:14:28.038373Z","iopub.status.busy":"2024-03-12T13:14:28.038037Z","iopub.status.idle":"2024-03-12T13:14:28.072909Z","shell.execute_reply":"2024-03-12T13:14:28.071853Z","shell.execute_reply.started":"2024-03-12T13:14:28.038344Z"},"trusted":true},"outputs":[],"source":["# Training Model\n","\n","def train(model, data_loader, save_addr, num_epoch = 50, learning_rate = 1e-4, overwrite = False):\n","    # Creating save folder\n","    create_dir(save_addr)\n","    model_addr = os.path.join(save_addr, 'model')\n","    create_dir(model_addr)\n","    loss_addr = os.path.join(save_addr, 'loss')\n","    create_dir(loss_addr)\n","\n","    # Parameters for training\n","    loss_fn = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n","    start_time = time.time()\n","    \n","    for epoch in range(num_epoch):\n","        batch_ct = 0\n","        epoch_loss = 0\n","\n","        # Loading previous model\n","        epoch_addr = os.path.join(model_addr, f'{epoch}.pt')\n","        epoch_loss_addr = os.path.join(loss_addr, f'{epoch}.pt')\n","\n","        if not overwrite and os.path.exists(epoch_addr) and os.path.exists(epoch_loss_addr):\n","            model.load_state_dict(torch.load(epoch_addr))\n","            epoch_loss = torch.load(epoch_loss_addr)\n","\n","            print(f\"Epoch: {epoch} Loaded\\t\\tLoss: {epoch_loss}\")\n","        else:\n","            # Training next epoch\n","            for x, y in data_loader:\n","                y_pred = model(x)\n","                loss = loss_fn(y_pred, y)\n","                epoch_loss += loss.item()\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","                batch_ct += 1\n","                print(f\"\\tBatch: {batch_ct}\\tLoss: {round(loss.item(), 6)}\\tTotal Loss: {round(epoch_loss/batch_ct, 6)}\\tTime: {time.time()-start_time}\")\n","\n","            # Saving model after each epoch\n","            torch.save(model.state_dict(), epoch_addr)\n","            torch.save(epoch_loss/batch_ct, epoch_loss_addr)\n","\n","            print(f\"Epoch: {epoch}\\tLoss: {round(epoch_loss/batch_ct, 6)}\\tTime: {time.time() - start_time}\")\n","\n","train(resnet_base_model, data_loader_train, base_model_result)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4584966,"sourceId":7824688,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"nbformat":4,"nbformat_minor":4}
