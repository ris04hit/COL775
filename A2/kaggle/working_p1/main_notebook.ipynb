{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch.cuda, torch.utils.data, torch.nn, torch\n",
    "import torchvision.transforms, torchvision.datasets.folder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addresses\n",
    "\n",
    "class Address:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Stores all the addresses used in project\n",
    "        '''\n",
    "        self.data = \"../input/clevertex/dataset\"\n",
    "        self.img_train = os.path.join(self.data, \"images/train\")\n",
    "        self.img_val = os.path.join(self.data, \"images/val\")\n",
    "        self.mask_train = os.path.join(self.data, \"masks/train\")\n",
    "        self.mask_val = os.path.join(self.data, \"masks/val\")\n",
    "\n",
    "    def create_dir(self, dir_list = None):\n",
    "        '''\n",
    "        Function to create directories in dir_list. If dir_list is None then create all directories of address.\n",
    "        '''\n",
    "        if dir_list == None:\n",
    "            dir_list = []\n",
    "        for address in dir_list:\n",
    "            if not os.path.exists(address):\n",
    "                os.mkdir(address)\n",
    "\n",
    "    def _delete_folder_content(self, folder_addr):\n",
    "        '''\n",
    "        Deletes all the content of folder_addr\n",
    "        '''\n",
    "        if os.path.exists(folder_addr):\n",
    "            for file in os.listdir(folder_addr):\n",
    "                if os.path.isdir(file):\n",
    "                    self._delete_folder_content(os.path.join(folder_addr, file))\n",
    "                else:\n",
    "                    os.remove(os.path.join(folder_addr, file))\n",
    "\n",
    "    def clean(self, file_list = None):\n",
    "        '''\n",
    "        Deletes all the content in file_list\n",
    "        '''\n",
    "        if file_list == None:\n",
    "            file_list = []\n",
    "        for address in file_list:\n",
    "            self._delete_folder_content(address)\n",
    "\n",
    "\n",
    "addr = Address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self, batch_size=64):\n",
    "        '''\n",
    "        Stores all Hyperparameters used for training of model\n",
    "        '''\n",
    "        # Training\n",
    "        self.batch_size = 2\n",
    "        self.resolution = (128, 128)\n",
    "\n",
    "        # Encoder\n",
    "        self.dim_input = 64\n",
    "\n",
    "        # Slot Attention\n",
    "        self.dim_slot = 64\n",
    "        self.dim_projected = 64\n",
    "        self.dim_mlp_slot = 128\n",
    "        self.num_slot = 11\n",
    "        self.num_iter_slot = 3\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_channel = 128\n",
    "\n",
    "param = HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed and CUDA\n",
    "\n",
    "random_seed = 68\n",
    "device = \"cpu\"\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    device = \"cuda\"\n",
    "print(f\"Working with device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, resolution, address_img, address_mask = None):\n",
    "        self.address_img = address_img\n",
    "        self.address_mask = address_mask\n",
    "        self.img_list = sorted(os.listdir(self.address_img))\n",
    "        if self.address_mask is not None:\n",
    "            self.mask_list = sorted(os.listdir(self.address_mask))\n",
    "        self.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                         torchvision.transforms.Resize(resolution)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_addr = os.path.join(self.address_img, self.img_list[idx])\n",
    "        img = torchvision.datasets.folder.default_loader(img_addr)\n",
    "\n",
    "        if self.address_mask is not None:\n",
    "            mask_addr = os.path.join(self.address_mask, self.mask_list[idx])\n",
    "            mask = torchvision.datasets.folder.default_loader(mask_addr)\n",
    "\n",
    "            return {\n",
    "                'img': self.transform(img).to(torch.float),\n",
    "                'mask': self.transform(mask).to(torch.float)\n",
    "            }\n",
    "        \n",
    "        return self.transform(img).to(torch.float)\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, address: Address, param: HyperParameters, device = device):\n",
    "        '''\n",
    "        Creates DataLoader and DataSet for both train and val split\n",
    "        '''\n",
    "        self.address = address\n",
    "        self.device = device\n",
    "\n",
    "        # Dataset for training\n",
    "        self.dataset_train_without_mask = DataSet(param.resolution, address.img_train)\n",
    "        self.dataset_val_without_mask = DataSet(param.resolution, address.img_val)\n",
    "\n",
    "        # DataLoader for training\n",
    "        self.loader_train_without_mask = torch.utils.data.DataLoader(self.dataset_train_without_mask,\n",
    "                                                                     batch_size=param.batch_size,\n",
    "                                                                     shuffle=True)\n",
    "        self.loader_val_without_mask = torch.utils.data.DataLoader(self.dataset_val_without_mask,\n",
    "                                                                   batch_size=param.batch_size,\n",
    "                                                                   shuffle=False)\n",
    "\n",
    "        # Dataset for evaluation\n",
    "        self.dataset_train_with_mask = DataSet(param.resolution, address.img_train, address.mask_train)\n",
    "        self.dataset_val_with_mask = DataSet(param.resolution, address.img_val, address.mask_val)\n",
    "\n",
    "        # DataLoader for training\n",
    "        self.loader_train_with_mask = torch.utils.data.DataLoader(self.dataset_train_with_mask,\n",
    "                                                                  batch_size=param.batch_size,\n",
    "                                                                  shuffle=False,\n",
    "                                                                  collate_fn=self.collate)\n",
    "        self.loader_val_with_mask = torch.utils.data.DataLoader(self.dataset_val_with_mask,\n",
    "                                                                batch_size=param.batch_size,\n",
    "                                                                shuffle=False,\n",
    "                                                                collate_fn=self.collate)\n",
    "\n",
    "    def collate(self, batch):\n",
    "        img = [elem['img'] for elem in batch]\n",
    "        mask = [elem['mask'] for elem in batch]\n",
    "\n",
    "        return {\n",
    "            'img': torch.stack(img),\n",
    "            'mask': torch.stack(mask)\n",
    "        }\n",
    "\n",
    "data = Data(addr, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "def create_grid(resolution):\n",
    "    '''\n",
    "    Creates the grid of size resolution with 4 channels. Each channel representing gradient in [0, 1] for one of the four direction.\n",
    "    '''\n",
    "    x_grad = np.linspace(0, 1, resolution[1])\n",
    "    y_grad = np.linspace(0, 1, resolution[0])\n",
    "    grid = np.meshgrid(y_grad, x_grad, indexing='ij')\n",
    "    grid = np.stack(grid, axis = -1)\n",
    "    grid = np.concatenate([grid, 1-grid], axis=-1)\n",
    "    grid = np.expand_dims(grid, axis=0)\n",
    "    return torch.tensor(grid, dtype=torch.float, requires_grad=False)\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, num_channel, device=device):\n",
    "        '''\n",
    "        Encodes input image into feature vectors\n",
    "        '''\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # CNN backbone of Encoder\n",
    "        self.cnn = torch.nn.Sequential(torch.nn.Conv2d(3, num_channel, 5, stride=1, padding='same', dtype=torch.float),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Conv2d(num_channel, num_channel, 5, stride=2, padding='same', dtype=torch.float),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Conv2d(num_channel, num_channel, 5, stride=2, padding='same', dtype=torch.float),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Conv2d(num_channel, num_channel, 5, stride=1, padding='same', dtype=torch.float),\n",
    "                                       torch.nn.ReLU())\n",
    "        \n",
    "        # Positional Embedding\n",
    "        self.register_buffer('grid', None)\n",
    "        self.embed = torch.nn.Linear(4, num_channel, dtype=torch.float)\n",
    "\n",
    "        # Flatten\n",
    "        self.flatten = torch.nn.Flatten(start_dim=1, end_dim=2)\n",
    "\n",
    "        # Layer Norm\n",
    "        self.layer_norm = torch.nn.LayerNorm(num_channel, dtype=torch.float)\n",
    "\n",
    "        # MLP\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(num_channel, num_channel, dtype=torch.float),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Linear(num_channel, num_channel, dtype=torch.float))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.cnn(x)     # CNN\n",
    "\n",
    "        x = x.permute((0, 3, 1, 2))     # Permuting Channel axis at the end\n",
    "\n",
    "        if self.grid is None:\n",
    "            self.grid = create_grid(x.shape[-2:]).to(self.device)\n",
    "        x = x + self.embed(self.grid)   # Positional Embedding\n",
    "\n",
    "        x = self.flatten(x)     # Flatten into feature vector\n",
    "\n",
    "        x = self.layer_norm(x)  # Layer Normalization\n",
    "\n",
    "        x = self.mlp(x)     # MLP\n",
    "\n",
    "        return x\n",
    "\n",
    "class SlotAttention(torch.nn.Module):\n",
    "    def __init__(self, dim_input, dim_slot, dim_projected, dim_mlp, num_slot, num_iter, epsilon, device=device):\n",
    "        '''\n",
    "        Implementes Slot Attention\n",
    "        '''\n",
    "        super(SlotAttention, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.dim_input = dim_input\n",
    "        self.dim_slot = dim_slot\n",
    "        self.dim_projected = dim_projected\n",
    "        self.dim_mlp = dim_mlp\n",
    "        self.num_slot = num_slot\n",
    "        self.num_iter = num_iter\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # Layer Norm\n",
    "        self.layer_norm_inp = torch.nn.LayerNorm(dim_input, dtype=torch.float)\n",
    "        self.layer_norm_slot = torch.nn.LayerNorm(dim_slot, dtype=torch.float)\n",
    "\n",
    "        # Slot Initialization Parameters\n",
    "        self.mean_slot = torch.nn.Parameter(torch.zeros(1, 1, self.dim_slot, dtype=torch.float))\n",
    "        self.log_std_slot = torch.nn.Parameter(torch.zeros(1, 1, self.dim_slot, dtype=torch.float))\n",
    "        torch.nn.init.xavier_uniform_(self.mean_slot)\n",
    "        torch.nn.init.xavier_uniform_(self.log_std_slot)\n",
    "\n",
    "        # Projection matrix\n",
    "        self.project_key = torch.nn.Linear(self.dim_input, self.dim_projected, bias=False, dtype=torch.float)\n",
    "        self.project_value = torch.nn.Linear(self.dim_input, self.dim_projected, bias=False, dtype=torch.float)\n",
    "        self.project_query = torch.nn.Linear(self.dim_slot, self.dim_projected, bias=False, dtype=torch.float)\n",
    "\n",
    "        # Slot update\n",
    "        self.gru = torch.nn.GRUCell(self.dim_projected, self.dim_slot)\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(self.dim_slot, self.dim_mlp),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Linear(self.dim_mlp, self.dim_slot))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm_inp(x)          # Layer Normalization\n",
    "\n",
    "        slots = self.mean_slot + torch.exp(self.log_std_slot)*torch.randn((x.shape[0], self.num_slot, self.dim_slot))      # Initializing slot\n",
    "\n",
    "        for t in range(self.num_iter):\n",
    "            slots_prev = slots\n",
    "            slots = self.layer_norm_slot(slots)         # Layer Normalization\n",
    "\n",
    "            # Computing Attention\n",
    "            attn = torch.matmul(self.project_key(x), self.project_query(slots).permute(0, 2, 1))   # Dot product of key and query\n",
    "            attn /= np.sqrt(self.dim_projected)                                                    # Setting SoftMax temperature\n",
    "            attn = torch.nn.functional.softmax(attn, dim=-1) + self.epsilon                        # Softmax with numerical stability\n",
    "\n",
    "            # Updating Slot\n",
    "            weights = attn/torch.sum(attn, dim=1, keepdim=True)                         # Calculating weights for update\n",
    "            updates = torch.bmm(weights.permute(0, 2, 1), self.project_value(x))        # Update array\n",
    "            slots = self.gru(updates.reshape(-1, self.dim_projected), slots_prev.reshape(-1, self.dim_slot))    # GRU update\n",
    "            slots = slots.reshape(-1, self.num_slot, self.dim_slot)\n",
    "            slots += self.mlp(slots)                                                    # Residual MLP update\n",
    "        \n",
    "        return slots\n",
    "\n",
    "class SBDecoder(torch.nn.Module):\n",
    "    def __init__(self, num_slot, dim_slot, resolution, num_channel, device=device):\n",
    "        '''\n",
    "        Implements Spatial Broadcast Decoder\n",
    "        '''\n",
    "        super(SBDecoder, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.num_slot = num_slot\n",
    "        self.dim_slot = dim_slot\n",
    "        self.resolution = resolution\n",
    "        self.num_channel = num_channel\n",
    "\n",
    "        # Grid for spatial feature\n",
    "        self.register_buffer('grid', 2*create_grid(resolution).permute(0, 3, 1, 2)[:, :2, :, :]-1)\n",
    "\n",
    "        # CNN Decoder\n",
    "        self.cnn = torch.nn.Sequential(torch.nn.Conv2d(2+dim_slot, num_channel, 5, stride=1, padding='same', dtype=torch.float),\n",
    "                                       torch.nn.ReLU(), \n",
    "                                       torch.nn.Conv2d(num_channel, num_channel, 5, stride=1, padding='same', dtype=torch.float),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Conv2d(num_channel, 4, 5, stride=1, padding='same', dtype=torch.float))\n",
    "\n",
    "    def forward(self, slots):\n",
    "        x = slots.reshape((-1, self.dim_slot, 1, 1))\n",
    "        \n",
    "        # Creating tiled latents\n",
    "        x = torch.tile(x, (1, 1, self.resolution[0], self.resolution[1]))\n",
    "        x = torch.concat([x, torch.tile(self.grid, (x.shape[0], 1, 1, 1))], dim=1)\n",
    "\n",
    "        # Decoding\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # Unstack and Split\n",
    "        x = x.reshape(-1, self.num_slot, 4, self.resolution[0], self.resolution[1])\n",
    "        img, mask = torch.split(x, [3, 1], dim=2)\n",
    "\n",
    "        # Reconstructing Image\n",
    "        mask = torch.nn.functional.softmax(mask, dim=1)\n",
    "        recon_img = torch.sum(img*mask, dim=1)\n",
    "        \n",
    "        return recon_img, img, mask, slots\n",
    "\n",
    "class ObjectDiscovery(torch.nn.Module):\n",
    "    def __init__(self, param: HyperParameters, device=device):\n",
    "        '''\n",
    "        Architecture enclosing encoder, slot attention, spatial broadcast decoder for object discovery task\n",
    "        '''\n",
    "        super(ObjectDiscovery, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.encoder = Encoder(param.dim_input, device=device)\n",
    "        self.slot_attention = SlotAttention(param.dim_input,\n",
    "                                            param.dim_slot,\n",
    "                                            param.dim_projected,\n",
    "                                            param.dim_mlp_slot,\n",
    "                                            param.num_slot,\n",
    "                                            param.num_iter_slot,\n",
    "                                            param.epsilon,\n",
    "                                            device=device)\n",
    "        self.decoder = SBDecoder(param.num_slot,\n",
    "                                 param.dim_slot,\n",
    "                                 param.resolution,\n",
    "                                 param.decoder_channel,\n",
    "                                 device=device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.slot_attention(x)\n",
    "        return self.decoder(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Model\n",
    "\n",
    "class LearnModel:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
