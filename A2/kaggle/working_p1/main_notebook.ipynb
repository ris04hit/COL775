{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch.cuda, torch.utils.data, torch.nn, torch.optim, torch\n",
    "import torchvision.transforms, torchvision.datasets.folder, torchvision.utils\n",
    "from sklearn.cluster import KMeans\n",
    "from cv2 import imread as img_read\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addresses\n",
    "\n",
    "class Address:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Stores all the addresses used in project\n",
    "        '''\n",
    "        # Inputs\n",
    "        self.data = \"../input/clevertex/dataset\"\n",
    "        self.img_train = os.path.join(self.data, \"images/train\")\n",
    "        self.img_val = os.path.join(self.data, \"images/val\")\n",
    "        self.mask_train = os.path.join(self.data, \"masks/train\")\n",
    "        self.mask_val = os.path.join(self.data, \"masks/val\")\n",
    "\n",
    "        # Models\n",
    "        self.model = \"results/\"\n",
    "        self.slot_attention = os.path.join(self.model, \"slot_attention\")\n",
    "\n",
    "        # Temp\n",
    "        self.temp = \"temp/\"\n",
    "\n",
    "    def create_dir(self, dir_list = None):\n",
    "        '''\n",
    "        Function to create directories in dir_list. If dir_list is None then create all directories of address.\n",
    "        '''\n",
    "        if dir_list == None:\n",
    "            dir_list = [self.model, self.temp, self.slot_attention]\n",
    "        for address in dir_list:\n",
    "            if not os.path.exists(address):\n",
    "                os.mkdir(address)\n",
    "\n",
    "    def _delete_folder_content(self, folder_addr):\n",
    "        '''\n",
    "        Deletes all the content of folder_addr\n",
    "        '''\n",
    "        if os.path.exists(folder_addr):\n",
    "            for file in os.listdir(folder_addr):\n",
    "                address = os.path.join(folder_addr, file)\n",
    "                if os.path.isdir(address):\n",
    "                    self._delete_folder_content(address)\n",
    "                    os.removedirs(address)\n",
    "                else:\n",
    "                    os.remove(address)\n",
    "\n",
    "    def clean(self, file_list = None):\n",
    "        '''\n",
    "        Deletes all the content in file_list\n",
    "        '''\n",
    "        if file_list == None:\n",
    "            file_list = [self.temp]\n",
    "        for address in file_list:\n",
    "            self._delete_folder_content(address)\n",
    "\n",
    "addr = Address()\n",
    "addr.clean()\n",
    "# addr.clean([addr.slot_attention])\n",
    "addr.create_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Stores all Hyperparameters used for training of model\n",
    "        '''\n",
    "        # Training\n",
    "        self.batch_size = 2\n",
    "        self.resolution = (128, 128)\n",
    "        self.num_epoch = 38\n",
    "        self.grad_clip = 1.0\n",
    "\n",
    "        # Data\n",
    "        self.num_train = 40000\n",
    "        self.num_val = 10000\n",
    "        self.train_step = self.num_epoch*(self.num_train//self.batch_size)\n",
    "        \n",
    "        # Learning Rate\n",
    "        self.lr = 4e-4\n",
    "        self.warmup_step = self.train_step//50\n",
    "        self.decay_step = self.train_step//5\n",
    "        self.decay_rate = 0.5\n",
    "\n",
    "        # Encoder\n",
    "        self.dim_input = 64\n",
    "        self.shift = 3\n",
    "\n",
    "        # Slot Attention\n",
    "        self.dim_slot = 64\n",
    "        self.dim_projected = 64\n",
    "        self.dim_mlp_slot = 128\n",
    "        self.num_slot = 11\n",
    "        self.num_iter_slot = 3\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_channel = 64\n",
    "\n",
    "        # Evaluation\n",
    "        self.ari_batch_size = 2\n",
    "\n",
    "    def lr_schedule(self, step):\n",
    "        '''\n",
    "        Getting learning rate as function of train steps completed\n",
    "        '''\n",
    "        if step <= self.warmup_step:\n",
    "            return step/self.warmup_step\n",
    "        else:\n",
    "            return self.decay_rate**((step-self.warmup_step)/self.decay_step)\n",
    "\n",
    "    def create_report(self, addr):\n",
    "        with open(os.path.join(addr, 'param.txt'), 'w') as file:\n",
    "            file.writelines([\n",
    "                f'Training:',\n",
    "                f'\\n\\tBatch Size:       {self.batch_size}',\n",
    "                f'\\n\\tResolution:       {self.resolution}',\n",
    "                f'\\n\\tNum Epoch:        {self.num_epoch}',\n",
    "                f'\\n\\tGrad Clip:        {self.grad_clip}',\n",
    "                f'\\n\\nData:',  \n",
    "                f'\\n\\tNum Train:        {self.num_train}',\n",
    "                f'\\n\\tNum Val:          {self.num_val}',\n",
    "                f'\\n\\tTrain Step:       {self.train_step}',\n",
    "                f'\\n\\nLearning Rate:',  \n",
    "                f'\\n\\tlr:               {self.lr}',\n",
    "                f'\\n\\tWarmup Step:      {self.warmup_step}',\n",
    "                f'\\n\\tDecay Step:       {self.decay_step}',\n",
    "                f'\\n\\tDecay Rate:       {self.decay_rate}',\n",
    "                f'\\n\\nEncoder:',  \n",
    "                f'\\n\\tDim Input:        {self.dim_input}',\n",
    "                f'\\n\\tShift:            {self.shift}',\n",
    "                f'\\n\\nSlot Attention:',\n",
    "                f'\\n\\tDim Slot:         {self.dim_slot}',\n",
    "                f'\\n\\tDim Projected:    {self.dim_projected}',\n",
    "                f'\\n\\tDim MLP slot:     {self.dim_mlp_slot}',\n",
    "                f'\\n\\tNum Slot:         {self.num_slot}',\n",
    "                f'\\n\\tNum Iter Slot:    {self.num_iter_slot}',\n",
    "                f'\\n\\tEpsilon:          {self.epsilon}',\n",
    "                f'\\n\\nDecoder:',  \n",
    "                f'\\n\\tDecoder Channel:  {self.decoder_channel}',\n",
    "                f'\\n\\nEvaluation:',\n",
    "                f'\\n\\tARI Batch Size:   {self.ari_batch_size}'\n",
    "            ])\n",
    "\n",
    "param = HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed and CUDA\n",
    "\n",
    "random_seed = 68\n",
    "device = \"cpu\"\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    device = \"cuda\"\n",
    "print(f\"Working with device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, resolution, address_img, address_mask = None):\n",
    "        self.address_img = address_img\n",
    "        self.address_mask = address_mask\n",
    "        self.img_list = sorted(os.listdir(self.address_img))\n",
    "        if self.address_mask is not None:\n",
    "            self.mask_list = sorted(os.listdir(self.address_mask))\n",
    "            self.mask_dict = {(0, 0, 0): 0}\n",
    "            self.num_category = 1\n",
    "        self.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                         torchvision.transforms.Resize(resolution, antialias=False)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_addr = os.path.join(self.address_img, self.img_list[idx])\n",
    "        img = torchvision.datasets.folder.default_loader(img_addr)\n",
    "\n",
    "        if self.address_mask is not None:\n",
    "            mask_addr = os.path.join(self.address_mask, self.mask_list[idx])\n",
    "            mask = img_read(mask_addr)\n",
    "            new_mask = torch.zeros(mask.shape[0], mask.shape[1], dtype=torch.long)\n",
    "            for i in range(mask.shape[0]):\n",
    "                for j in range(mask.shape[1]):\n",
    "                    color = tuple(mask[i, j, :])\n",
    "                    if color not in self.mask_dict:\n",
    "                        self.mask_dict[color] = self.num_category\n",
    "                        self.num_category += 1\n",
    "                    new_mask[i,j] = self.mask_dict[color]\n",
    "\n",
    "            return {\n",
    "                'img': self.transform(img).to(torch.float),\n",
    "                'mask': new_mask\n",
    "            }\n",
    "        \n",
    "        return self.transform(img).to(torch.float)\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, address: Address, param: HyperParameters, device = device):\n",
    "        '''\n",
    "        Creates DataLoader and DataSet for both train and val split\n",
    "        '''\n",
    "        self.address = address\n",
    "        self.device = device\n",
    "\n",
    "        # Dataset for training\n",
    "        self.dataset_train_without_mask = DataSet(param.resolution, address.img_train)\n",
    "        self.dataset_val_without_mask = DataSet(param.resolution, address.img_val)\n",
    "\n",
    "        # DataLoader for training\n",
    "        self.loader_train_without_mask = torch.utils.data.DataLoader(self.dataset_train_without_mask,\n",
    "                                                                     batch_size=param.batch_size,\n",
    "                                                                     shuffle=True)\n",
    "        self.loader_val_without_mask = torch.utils.data.DataLoader(self.dataset_val_without_mask,\n",
    "                                                                   batch_size=param.batch_size,\n",
    "                                                                   shuffle=False)\n",
    "\n",
    "        # Dataset for evaluation\n",
    "        self.dataset_train_with_mask = DataSet(param.resolution, address.img_train, address.mask_train)\n",
    "        self.dataset_val_with_mask = DataSet(param.resolution, address.img_val, address.mask_val)\n",
    "\n",
    "        # DataLoader for evaluation\n",
    "        self.loader_train_with_mask = torch.utils.data.DataLoader(self.dataset_train_with_mask,\n",
    "                                                                  batch_size=param.ari_batch_size,\n",
    "                                                                  shuffle=False,\n",
    "                                                                  collate_fn=self.collate,\n",
    "                                                                  num_workers=4)\n",
    "        self.loader_val_with_mask = torch.utils.data.DataLoader(self.dataset_val_with_mask,\n",
    "                                                                batch_size=param.ari_batch_size,\n",
    "                                                                shuffle=False,\n",
    "                                                                collate_fn=self.collate)\n",
    "\n",
    "    def collate(self, batch):\n",
    "        img = [elem['img'] for elem in batch]\n",
    "        mask = [elem['mask'] for elem in batch]\n",
    "\n",
    "        return {\n",
    "            'img': torch.stack(img),\n",
    "            'mask': torch.stack(mask)\n",
    "        }\n",
    "\n",
    "data = Data(addr, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "def create_grid(resolution):\n",
    "    '''\n",
    "    Creates the grid of size resolution with 4 channels. Each channel representing gradient in [0, 1] for one of the four direction.\n",
    "    '''\n",
    "    x_grad = np.linspace(0, 1, resolution[1])\n",
    "    y_grad = np.linspace(0, 1, resolution[0])\n",
    "    grid = np.meshgrid(y_grad, x_grad, indexing='ij')\n",
    "    grid = np.stack(grid, axis = -1)\n",
    "    grid = np.concatenate([grid, 1-grid], axis=-1)\n",
    "    grid = np.expand_dims(grid, axis=0)\n",
    "    return torch.tensor(grid, dtype=torch.float, requires_grad=False)\n",
    "\n",
    "class ResBlock(torch.nn.Module):\n",
    "    def __init__(self, num_channel, kernel_size=5, stride=1, padding='same'):\n",
    "        '''\n",
    "        Initializes a Resnet Block with one convolution layer having ReLU activation\n",
    "        '''\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(num_channel, num_channel, kernel_size, stride=stride, padding=padding, dtype=torch.float)\n",
    "        self.norm1 = torch.nn.InstanceNorm2d(num_channel)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(num_channel, num_channel, kernel_size, stride=1, padding='same', dtype=torch.float)\n",
    "        self.norm2 = torch.nn.InstanceNorm2d(num_channel)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "\n",
    "        self.project = True if (stride != 1) else False\n",
    "        if self.project:\n",
    "            self.conv_project = torch.nn.Conv2d(num_channel, num_channel, kernel_size, stride=stride, padding=padding, dtype=torch.float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "\n",
    "        # First convolution\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.activation1(x)\n",
    "\n",
    "        # Second Convolution\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = x + (self.conv_project(res) if self.project else res)\n",
    "        x = self.activation2(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, num_channel, shift, device=device):\n",
    "        '''\n",
    "        Encodes input image into feature vectors\n",
    "        '''\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.num_channel = num_channel\n",
    "        self.shift = shift\n",
    "\n",
    "        # CNN backbone of Encoder    \n",
    "        cnn = [torch.nn.Conv2d(3, num_channel, 5, stride=1, padding='same', dtype=torch.float), torch.nn.ReLU()]\n",
    "        for _ in range(shift):\n",
    "            cnn.append(ResBlock(num_channel, 5, stride=2, padding=2))\n",
    "            cnn.append(ResBlock(num_channel, 5, stride=1, padding='same'))\n",
    "        cnn.append(ResBlock(num_channel, 5, stride=1, padding='same'))\n",
    "        self.cnn = torch.nn.Sequential(*cnn)\n",
    "        \n",
    "        # Positional Embedding\n",
    "        self.register_buffer('grid', None)\n",
    "        self.embed = torch.nn.Linear(4, num_channel, dtype=torch.float)\n",
    "\n",
    "        # Flatten\n",
    "        self.flatten = torch.nn.Flatten(start_dim=1, end_dim=2)\n",
    "\n",
    "        # Layer Norm\n",
    "        self.layer_norm = torch.nn.LayerNorm(num_channel, dtype=torch.float)\n",
    "\n",
    "        # MLP\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(num_channel, num_channel, dtype=torch.float),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Linear(num_channel, num_channel, dtype=torch.float))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.cnn(x)     # CNN\n",
    "\n",
    "        x = x.permute((0, 2, 3, 1))     # Permuting Channel axis at the end\n",
    "\n",
    "        if self.grid is None:\n",
    "            self.grid = create_grid(x.shape[1:3]).to(self.device)\n",
    "        x = x + self.embed(self.grid)   # Positional Embedding\n",
    "\n",
    "        x = self.flatten(x)     # Flatten into feature vector\n",
    "\n",
    "        x = self.layer_norm(x)  # Layer Normalization\n",
    "\n",
    "        x = self.mlp(x)     # MLP\n",
    "\n",
    "        return x\n",
    "\n",
    "class SlotAttention(torch.nn.Module):\n",
    "    def __init__(self, dim_input, dim_slot, dim_projected, dim_mlp, num_slot, num_iter, epsilon, device=device):\n",
    "        '''\n",
    "        Implementes Slot Attention\n",
    "        '''\n",
    "        super(SlotAttention, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.dim_input = dim_input\n",
    "        self.dim_slot = dim_slot\n",
    "        self.dim_projected = dim_projected\n",
    "        self.dim_mlp = dim_mlp\n",
    "        self.num_slot = num_slot\n",
    "        self.num_iter = num_iter\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # Layer Norm\n",
    "        self.layer_norm_inp = torch.nn.LayerNorm(dim_input, dtype=torch.float)\n",
    "        self.layer_norm_slot = torch.nn.LayerNorm(dim_slot, dtype=torch.float)\n",
    "\n",
    "        # Slot Initialization Parameters\n",
    "        self.slots = torch.nn.Parameter(torch.randn(1, self.num_slot, self.dim_slot, dtype=torch.float))\n",
    "\n",
    "        # Projection matrix\n",
    "        self.project_key = torch.nn.Linear(self.dim_input, self.dim_projected, bias=False, dtype=torch.float)\n",
    "        self.project_value = torch.nn.Linear(self.dim_input, self.dim_projected, bias=False, dtype=torch.float)\n",
    "        self.project_query = torch.nn.Linear(self.dim_slot, self.dim_projected, bias=False, dtype=torch.float)\n",
    "\n",
    "        # Slot update\n",
    "        self.gru = torch.nn.GRUCell(self.dim_projected, self.dim_slot)\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(self.dim_slot, self.dim_mlp),\n",
    "                                       torch.nn.ReLU(),\n",
    "                                       torch.nn.Linear(self.dim_mlp, self.dim_slot))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm_inp(x)          # Layer Normalization\n",
    "\n",
    "        slots = torch.tile(self.slots, dims = (x.shape[0], 1, 1))                  # Initializing Slot\n",
    "\n",
    "        for t in range(self.num_iter):\n",
    "            slots_prev = slots\n",
    "            slots = self.layer_norm_slot(slots)         # Layer Normalization\n",
    "\n",
    "            # Computing Attention\n",
    "            attn = torch.matmul(self.project_key(x), self.project_query(slots).permute(0, 2, 1))   # Dot product of key and query\n",
    "            attn /= np.sqrt(self.dim_projected)                                                    # Setting SoftMax temperature\n",
    "            attn = torch.nn.functional.softmax(attn, dim=-1) + self.epsilon                        # Softmax with numerical stability\n",
    "\n",
    "            # Updating Slot\n",
    "            weights = attn/torch.sum(attn, dim=1, keepdim=True)                         # Calculating weights for update\n",
    "            updates = torch.bmm(weights.permute(0, 2, 1), self.project_value(x))        # Update array\n",
    "            slots = self.gru(updates.reshape(-1, self.dim_projected), slots_prev.reshape(-1, self.dim_slot))    # GRU update\n",
    "            slots = slots.reshape(-1, self.num_slot, self.dim_slot)\n",
    "            slots = slots + self.mlp(slots)                                                    # Residual MLP update\n",
    "        \n",
    "        return slots\n",
    "\n",
    "class SBDecoder(torch.nn.Module):\n",
    "    def __init__(self, num_slot, dim_slot, resolution, num_channel, shift, device=device):\n",
    "        '''\n",
    "        Implements Spatial Broadcast Decoder\n",
    "        '''\n",
    "        super(SBDecoder, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.num_slot = num_slot\n",
    "        self.dim_slot = dim_slot\n",
    "        self.resolution = resolution\n",
    "        self.num_channel = num_channel\n",
    "        self.shift = shift\n",
    "        self.shifted_resolution = (resolution[0]>>shift, resolution[1]>>shift)\n",
    "\n",
    "        # Grid for spatial feature\n",
    "        self.register_buffer('grid', 2*create_grid(self.shifted_resolution).permute(0, 3, 1, 2)[:, :2, :, :]-1)\n",
    "\n",
    "        # CNN Decoder\n",
    "        cnn = [torch.nn.Conv2d(2+dim_slot, num_channel, 5, stride=1, padding='same', dtype=torch.float), torch.nn.ReLU()]\n",
    "        for _ in range(shift):\n",
    "            cnn.append(torch.nn.ConvTranspose2d(num_channel, num_channel, 5, stride=2, padding=2, output_padding=1, dtype=torch.float))\n",
    "            cnn.append(torch.nn.ReLU())\n",
    "        cnn.append(torch.nn.ConvTranspose2d(num_channel, num_channel, 5, stride=1, padding=2, dtype=torch.float))\n",
    "        cnn.append(torch.nn.ReLU())\n",
    "        cnn.append(torch.nn.ConvTranspose2d(num_channel, 4, 5, stride=1, padding=2, dtype=torch.float))\n",
    "        self.cnn = torch.nn.Sequential(*cnn)\n",
    "\n",
    "    def forward(self, slots):\n",
    "        x = slots.reshape((-1, self.dim_slot, 1, 1))\n",
    "        \n",
    "        # Creating tiled latents\n",
    "        x = torch.tile(x, (1, 1, self.shifted_resolution[0], self.shifted_resolution[1]))\n",
    "        x = torch.concat([x, torch.tile(self.grid, (x.shape[0], 1, 1, 1))], dim=1)\n",
    "\n",
    "        # Decoding\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # Unstack and Split\n",
    "        x = x.reshape(-1, self.num_slot, 4, self.resolution[0], self.resolution[1])\n",
    "        img, mask = torch.split(x, [3, 1], dim=2)\n",
    "\n",
    "        # Reconstructing Image\n",
    "        mask = torch.nn.functional.softmax(mask, dim=1)\n",
    "        recon_img = torch.sum(img*mask, dim=1)\n",
    "        \n",
    "        return recon_img, img, mask.squeeze(2), slots\n",
    "\n",
    "class ObjectDiscovery(torch.nn.Module):\n",
    "    def __init__(self, param: HyperParameters, device=device):\n",
    "        '''\n",
    "        Architecture enclosing encoder, slot attention, spatial broadcast decoder for object discovery task\n",
    "        '''\n",
    "        super(ObjectDiscovery, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.encoder = Encoder(param.dim_input, param.shift, device=device)\n",
    "        self.slot_attention = SlotAttention(param.dim_input,\n",
    "                                            param.dim_slot,\n",
    "                                            param.dim_projected,\n",
    "                                            param.dim_mlp_slot,\n",
    "                                            param.num_slot,\n",
    "                                            param.num_iter_slot,\n",
    "                                            param.epsilon,\n",
    "                                            device=device)\n",
    "        self.decoder = SBDecoder(param.num_slot,\n",
    "                                 param.dim_slot,\n",
    "                                 param.resolution,\n",
    "                                 param.decoder_channel,\n",
    "                                 param.shift,\n",
    "                                 device=device)\n",
    "        \n",
    "    def forward(self, x, slot_only = False):\n",
    "        x = self.encoder(x)\n",
    "        x = self.slot_attention(x)\n",
    "        if slot_only:\n",
    "            return x\n",
    "        return self.decoder(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric\n",
    "def ARI(original_mask, predicted_mask, transform):\n",
    "    max_cat = data.dataset_val_with_mask.num_category\n",
    "    num_slot = predicted_mask.shape[1]\n",
    "\n",
    "    # Flattening and Reshaping to get masks of shape (Batch Size, H*W)\n",
    "    orig_mask = torch.flatten(original_mask, start_dim=1, end_dim=2)\n",
    "    pred_mask = torch.flatten(torch.argmax(transform(predicted_mask), dim=1), start_dim=1, end_dim=2)\n",
    "\n",
    "    # One Hot Encoding\n",
    "    pred_mask_oh = torch.nn.functional.one_hot(pred_mask, num_classes=num_slot).to(torch.float)\n",
    "    orig_mask_oh = torch.nn.functional.one_hot(orig_mask, num_classes=max_cat)[:, :, 1:].to(torch.float)       # Removing Background\n",
    "\n",
    "    # Number of non Background Points\n",
    "    n_points = torch.count_nonzero(orig_mask_oh)\n",
    "\n",
    "    # Calculating number of objects in common\n",
    "    nij = torch.bmm(orig_mask_oh.permute(0, 2, 1), pred_mask_oh)\n",
    "    ai = torch.sum(nij, dim=1)\n",
    "    bj = torch.sum(nij, dim=2)\n",
    "\n",
    "    # Calculating ARI\n",
    "    rindex = torch.sum(nij*(nij-1), dim=(1, 2))\n",
    "    aindex = torch.sum(ai*(ai-1), dim=1)\n",
    "    bindex = torch.sum(bj*(bj-1), dim=1)\n",
    "    expected_rindex = aindex*bindex / (n_points*(n_points-1))\n",
    "    max_rindex = (aindex + bindex)/2\n",
    "\n",
    "    return torch.mean((rindex - expected_rindex)/(max_rindex - expected_rindex)).item()\n",
    "\n",
    "# Learning Model\n",
    "class LearnModel:\n",
    "    def __init__(self, model: torch.nn.Module, model_addr, data=data, param=param, device=device):\n",
    "        '''\n",
    "        Train, Evaluate and Predict\n",
    "        '''\n",
    "        \n",
    "        self.data = data\n",
    "        self.param = param\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.model_addr = model_addr\n",
    "\n",
    "        # Addresses\n",
    "        self.loss_addr = os.path.join(self.model_addr, 'loss.npz')\n",
    "        self.epoch_addr = lambda epoch: os.path.join(self.model_addr, f'model/{epoch}.pth')\n",
    "        self.scheduler_addr = lambda epoch: os.path.join(self.model_addr, f'scheduler/{epoch}.pth')\n",
    "        self.ari_addr = os.path.join(model_addr, \"ARI.txt\")\n",
    "        self.slot_addr = os.path.join(model_addr, \"slots.npz\")\n",
    "        self.img_addr = os.path.join(model_addr, \"gen_img\")\n",
    "        self.vis_addr = os.path.join(model_addr, \"visualize\")\n",
    "        addr.create_dir([os.path.join(self.model_addr, 'model'),\n",
    "                         os.path.join(self.model_addr, 'scheduler'),\n",
    "                         self.img_addr,\n",
    "                         self.vis_addr])\n",
    "\n",
    "    def train(self, epoch_log = True, batch_log = True, overwrite = False):\n",
    "        optimizer = torch.optim.Adam(params=self.model.parameters(), lr=self.param.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = self.param.lr_schedule)\n",
    "        loss_fn = torch.nn.MSELoss().to(device)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Loss arr\n",
    "        if os.path.exists(self.loss_addr):\n",
    "            loss_arr = np.load(self.loss_addr)\n",
    "            train_loss_arr = list(loss_arr['train'])\n",
    "            val_loss_arr = list(loss_arr['val'])\n",
    "        else:\n",
    "            train_loss_arr = []\n",
    "            val_loss_arr = []\n",
    "\n",
    "        if overwrite:\n",
    "            addr.clean([self.model_addr])\n",
    "        \n",
    "        for epoch in range(self.param.num_epoch):\n",
    "            epoch_addr = self.epoch_addr(epoch)\n",
    "            scheduler_addr = self.scheduler_addr(epoch)\n",
    "\n",
    "            # Loading Model if present\n",
    "            if os.path.exists(epoch_addr) and os.path.exists(scheduler_addr):\n",
    "                self.model.load_state_dict(torch.load(epoch_addr), strict=False)\n",
    "                scheduler.load_state_dict(torch.load(scheduler_addr))\n",
    "                print(f\"Loaded model and scheduler at epoch {epoch}\")\n",
    "                continue\n",
    "\n",
    "            # Training Model\n",
    "            train_loss = self.train_epoch(optimizer, scheduler, loss_fn, batch_log=batch_log)\n",
    "            if epoch_log:\n",
    "                print(f'Epoch: {epoch}\\tTrain Loss: {train_loss}\\tTime: {time.time()-start_time}')\n",
    "\n",
    "            # Validating Model\n",
    "            val_loss = self.validate_epoch(loss_fn, self.data.loader_val_without_mask, batch_log=batch_log)\n",
    "            if epoch_log:\n",
    "                print(f'Epoch: {epoch}\\tVal Loss: {val_loss}\\tTime: {time.time()-start_time}')\n",
    "\n",
    "            # Saving data\n",
    "            train_loss_arr.append(train_loss)\n",
    "            val_loss_arr.append(val_loss)\n",
    "            np.savez_compressed(self.loss_addr, train=np.array(train_loss_arr), val=np.array(val_loss_arr))     # Saving Loss Array\n",
    "            torch.save(self.model.state_dict(), epoch_addr)     # Saving Model\n",
    "            torch.save(scheduler.state_dict(), scheduler_addr)  # Saving Scheduler\n",
    "\n",
    "            # Printing blank line between each epoch in Log\n",
    "            if epoch_log:\n",
    "                print()\n",
    "        \n",
    "    def train_epoch(self, optimizer, scheduler, loss_fn, batch_log):\n",
    "        '''\n",
    "        Trains model for one epoch\n",
    "        '''\n",
    "        epoch_loss = 0\n",
    "        batch_ct = 0\n",
    "        dataloader = self.data.loader_train_without_mask\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.model.train()          # Set Model to train Mode\n",
    "\n",
    "        for data in dataloader:\n",
    "            # Copying data to cuda\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Forward Propagation\n",
    "            recon_img, img, mask, slots = self.model(data)\n",
    "\n",
    "            # Computing Loss\n",
    "            loss = loss_fn(data, recon_img)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Back Propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.param.grad_clip)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update batch count\n",
    "            batch_ct += 1\n",
    "\n",
    "            if batch_log and batch_ct%50 == 0:\n",
    "                print(f\"\\tBatch {batch_ct}\\tLoss: {epoch_loss/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        return epoch_loss/batch_ct\n",
    "    \n",
    "    def validate_epoch(self, loss_fn, dataloader, batch_log):\n",
    "        '''\n",
    "        Calculates Loss on data in given dataloader\n",
    "        '''\n",
    "        epoch_loss = 0\n",
    "        batch_ct = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.model.eval()           # Set Model to eval mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                # Copying data to cuda\n",
    "                data = data.to(device)\n",
    "\n",
    "                # Forward Propagation\n",
    "                recon_img, img, mask, slots = self.model(data)\n",
    "\n",
    "                # Computing Loss\n",
    "                loss = loss_fn(data, recon_img)\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # Update batch count\n",
    "                batch_ct += 1\n",
    "\n",
    "                if batch_log and batch_ct%125 == 0:\n",
    "                    print(f\"\\tBatch {batch_ct}\\tLoss: {epoch_loss/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        return epoch_loss/batch_ct\n",
    "\n",
    "    def plot_loss(self, addr = None):\n",
    "        '''\n",
    "        Plots Loss vs number of epochs\n",
    "        '''\n",
    "        if not os.path.exists(self.loss_addr):\n",
    "            raise Exception(\"No Loss Array\")\n",
    "        loss_arr = np.load(self.loss_addr)\n",
    "        train_arr, val_arr = loss_arr['train'], loss_arr['val']\n",
    "        num_epoch = train_arr.shape[0]\n",
    "        x_arr = np.linspace(1, num_epoch, num_epoch)\n",
    "\n",
    "        if addr is None:\n",
    "            addr = os.path.join(self.model_addr, 'loss_curve')\n",
    "\n",
    "        plt.title(\"Loss Curve\")\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"MSE Loss\")\n",
    "        plt.plot(x_arr, train_arr, label='Train')\n",
    "        plt.plot(x_arr, val_arr, label='Val')\n",
    "        plt.legend()\n",
    "        plt.savefig(addr)\n",
    "\n",
    "    def best_model(self):\n",
    "        '''\n",
    "        Returns Best Model as well as changes self.model in place to best model\n",
    "        '''\n",
    "        if not os.path.exists(self.loss_addr):\n",
    "            raise Exception(\"No Loss Array\")\n",
    "        loss_arr = np.load(self.loss_addr)\n",
    "        best_epoch = np.argmin(loss_arr['val'])\n",
    "        self.model.load_state_dict(torch.load(self.epoch_addr(best_epoch)), strict=False)\n",
    "        return self.model\n",
    "    \n",
    "    def ARI_score(self, dataloader = None, log=True):\n",
    "        '''\n",
    "        Calculates ARI score for given dataloader (default validation dataset)\n",
    "        '''\n",
    "        self.model.eval()       # Set Model to eval mode\n",
    "        ari_score = 0\n",
    "        batch_ct = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        transform = None\n",
    "\n",
    "        if dataloader is None:\n",
    "            dataloader = self.data.loader_val_with_mask\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                # Loading Data\n",
    "                img_orig, mask_orig = data['img'].to(device), data['mask'].to(device)\n",
    "\n",
    "                # Forward Propagation\n",
    "                recon_img, img, mask_pred, slots = self.model(img_orig)\n",
    "\n",
    "                # Calculating ARI score\n",
    "                if transform is None:\n",
    "                    transform = torchvision.transforms.Resize(mask_orig.shape[1:], antialias=False)\n",
    "                ari_score += ARI(mask_orig, mask_pred, transform)\n",
    "                batch_ct += 1\n",
    "\n",
    "                # Log\n",
    "                if log and batch_ct%2 == 0:\n",
    "                    print(f\"Batch: {batch_ct}\\tARI score: {ari_score/batch_ct}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        with open(self.ari_addr, mode='w') as file:\n",
    "            file.write(f\"ARI Score: {ari_score/batch_ct}\\n\")\n",
    "\n",
    "    def _kmean_slot(self, log):\n",
    "        '''\n",
    "        Use scikit Kmean to cluster slots\n",
    "        '''\n",
    "        batch_ct = 0\n",
    "        start_time = time.time()\n",
    "        dataloader = self.data.loader_train_without_mask\n",
    "\n",
    "        self.model.eval()           # Set Model to eval mode\n",
    "        slot_arr = torch.tensor([], device=self.device)\n",
    "\n",
    "        # Concatenating all slots\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                # Copying data to cuda\n",
    "                data = data.to(device)\n",
    "\n",
    "                # Forward Propagation\n",
    "                slots = self.model(data, slot_only = True)\n",
    "\n",
    "                # Updating slot_arr\n",
    "                slot_arr = torch.concat((slot_arr, slots.reshape(-1, self.param.dim_slot)))\n",
    "\n",
    "                # Update batch count\n",
    "                batch_ct += 1\n",
    "\n",
    "                if log and batch_ct%125 == 0:\n",
    "                    print(f\"Computed Slot for Batch {batch_ct}\\tNumSlot: {slot_arr.shape}\\tTime: {time.time()-start_time}\")\n",
    "\n",
    "        # K-Mean Cluster\n",
    "        slot_arr = slot_arr.to(\"cpu\").detach().numpy()\n",
    "        kmean = KMeans(n_clusters=self.param.num_slot, n_init='auto', random_state=random_seed)\n",
    "        kmean.fit(slot_arr)\n",
    "        label = kmean.labels_\n",
    "        np.savez_compressed(self.slot_addr, slot=slot_arr, label=label)\n",
    "\n",
    "    def _sample_slot(self, slot_dict, slot_arr, batch_size):\n",
    "        '''\n",
    "        Randomly Samples slot from each cluster of kmean\n",
    "        '''\n",
    "        batch_slots = []\n",
    "        for _ in range(batch_size):\n",
    "            slots = []\n",
    "            for val in slot_dict:\n",
    "                slots.append(slot_arr[np.random.choice(slot_dict[val])])\n",
    "            batch_slots.append(np.stack(slots))\n",
    "        return np.stack(batch_slots)\n",
    "\n",
    "    def slot_lib(self, overwrite = False, log=True):\n",
    "        '''\n",
    "        Creates a slot library and generates images from it\n",
    "        '''\n",
    "        # Checking if trained model of kmean already present\n",
    "        if overwrite or not os.path.exists(self.slot_addr):\n",
    "            self._kmean_slot(log=log)\n",
    "        saved_arr = np.load(self.slot_addr)\n",
    "        slot_arr = saved_arr['slot']\n",
    "        label = saved_arr['label']\n",
    "        print(\"Loaded slot array and labels\")\n",
    "\n",
    "        # Storing slots labelwise\n",
    "        unique_values = np.unique(label)\n",
    "        slot_dict = {}\n",
    "        for val in unique_values:\n",
    "            slot_dict[val] = np.argwhere(label == val).flatten()\n",
    "\n",
    "        # Generating images via Random Slot Sampling\n",
    "        with torch.no_grad():\n",
    "            num_generate = len(self.data.dataset_val_without_mask)\n",
    "            ct_img = 0\n",
    "            for i in range(0, num_generate, self.param.batch_size):\n",
    "                batch_size = min(num_generate-i, self.param.batch_size)\n",
    "                generated_slots = torch.tensor(self._sample_slot(slot_dict, slot_arr, batch_size), dtype=torch.float32, device=self.device)\n",
    "                generated_img, _, _, _ = self.model.decoder(generated_slots)\n",
    "                for img in generated_img:\n",
    "                    torchvision.utils.save_image(img, os.path.join(self.img_addr, f'{ct_img}.png'))\n",
    "                    ct_img += 1\n",
    "\n",
    "    def visualize(self):\n",
    "        for data in self.data.loader_train_without_mask:\n",
    "            with torch.no_grad():\n",
    "                recon_img, img, mask, slots = self.model(data.to(device))\n",
    "                mask_oh = torch.nn.functional.one_hot(torch.argmax(mask, dim=1), self.param.num_slot).permute(0, 3, 1, 2)\n",
    "\n",
    "            for i in range(data.shape[0]):\n",
    "                img_path = os.path.join(self.vis_addr, f'{i}')\n",
    "                addr.create_dir([img_path])\n",
    "                torchvision.utils.save_image(data[i], os.path.join(img_path, 'orig.png'))\n",
    "                torchvision.utils.save_image(recon_img[i], os.path.join(img_path, 'regen.png'))\n",
    "                for slot_num in range(img.shape[1]):\n",
    "                    torchvision.utils.save_image(img[i, slot_num], os.path.join(img_path, f'img{slot_num}.png'))\n",
    "                    torchvision.utils.save_image(mask_oh[i, slot_num]*img[i, slot_num], os.path.join(img_path, f'threshold_img{slot_num}.png'))\n",
    "            break     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ObjectDiscovery(param, device=device).to(device)\n",
    "learner = LearnModel(model, addr.slot_attention)\n",
    "learner.param.create_report(learner.model_addr)\n",
    "learner.train()\n",
    "learner.plot_loss()\n",
    "learner.best_model()\n",
    "learner.ARI_score()\n",
    "learner.slot_lib()\n",
    "learner.visualize()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
